{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python389jvsc74a57bd0303f4f94c3b299c215f3066923e10ebd3683e42f3be4d2a62ff11651779c3d00",
   "display_name": "Python 3.8.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "303f4f94c3b299c215f3066923e10ebd3683e42f3be4d2a62ff11651779c3d00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# I) tensors Basics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "#### Difference between numpy ndarray and tensors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24]\ntf.Tensor(\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24], shape=(25,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.arange(0,25)\n",
    "print(x1)\n",
    "x2 = tf.constant(x, dtype=tf.int32)\n",
    "print(x2)"
   ]
  },
  {
   "source": [
    "#### 1. There are two way to declare tensors\n",
    "- tf.Variable(): mutable/changeable.\n",
    "- tf.constant():  imutable/un-changeable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<tf.Variable 'Variable:0' shape=(25,) dtype=int32, numpy=\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24])>\ntf.Tensor(\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24], shape=(25,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.Variable(x1)\n",
    "tensor2 = tf.constant(x2)\n",
    "print(tensor1)\n",
    "print(tensor2)"
   ]
  },
  {
   "source": [
    "#### 2. One feature of tensors is that they can be reshaped. When reshpaing, make sure you consider dimensions that will include all of the values of the tensor."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]], shape=(5, 5), dtype=int32)\ntf.Tensor(\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]], shape=(5, 5), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = tf.reshape(tensor1, shape=(5,5))\n",
    "tensor2 = tf.reshape(tensor2, shape=(5,5))\n",
    "print(tensor1)\n",
    "print(tensor2)"
   ]
  },
  {
   "source": [
    "#### 3. You can define the shape in `tf.constant()`, but cant do that for `tf.Variable()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The initial value's shape ((4,)) is not compatible with the explicitly supplied `shape` argument ((2, 2)).\ntf.Tensor(\n[[1 2]\n [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # This will produce a ValueError\n",
    "    tf.Variable([1,2,3,4], shape=(2,2))\n",
    "except ValueError as v:\n",
    "    # See what the ValueError says\n",
    "    print(v)\n",
    "\n",
    "temp2 = tf.constant([1,2,3,4], shape=(2,2))\n",
    "print(temp2)"
   ]
  },
  {
   "source": [
    "#### 4. You can also change data type of the values within the tensor."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[1. 2.]\n [3. 4.]], shape=(2, 2), dtype=float32)\ntf.Tensor(\n[[1 2]\n [3 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.cast(temp2, dtype=tf.float32)\n",
    "x2 = tf.cast(temp2, dtype=tf.int32)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "source": [
    "#### 5. Basic Operations\n",
    "\n",
    "### a. using tf functions.\n",
    "- You can  print out only the values from the tensors using `tensor.numpy()` syntax."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[10 12 14 16 18 20 22 24 26 28]\n[10 10 10 10 10 10 10 10 10 10]\n[  0  11  24  39  56  75  96 119 144 171]\n[        inf 11.          6.          4.33333333  3.5         3.\n  2.66666667  2.42857143  2.25        2.11111111]\n[ 0  1  4  9 16 25 36 49 64 81]\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = np.arange(0,10), np.arange(10, 20)\n",
    "summ = tf.add(x1, x2)\n",
    "sub = tf.subtract(x2, x1)\n",
    "mul = tf.multiply(x1, x2)\n",
    "div = tf.divide(x2, x1)\n",
    "x1_sqr = tf.square(x1)\n",
    "print(summ.numpy())\n",
    "print(sub.numpy())\n",
    "print(mul.numpy())\n",
    "print(div.numpy())\n",
    "print(x1_sqr.numpy())\n"
   ]
  },
  {
   "source": [
    "### b. using mathmetical operators"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[10 12 14 16 18 20 22 24 26 28]\n[10 10 10 10 10 10 10 10 10 10]\n[  0  11  24  39  56  75  96 119 144 171]\n[0.         0.09090909 0.16666667 0.23076923 0.28571429 0.33333333\n 0.375      0.41176471 0.44444444 0.47368421]\n"
     ]
    }
   ],
   "source": [
    "x1, x2 = tf.Variable(np.arange(0,10)), tf.Variable(np.arange(10, 20))\n",
    "\n",
    "summ = x1 + x2\n",
    "sub = x2 - x1\n",
    "mul = x1 * x2\n",
    "div = x1 / x2\n",
    "print(summ.numpy())\n",
    "print(sub.numpy())\n",
    "print(mul.numpy())\n",
    "print(div.numpy())"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# II) GradientTape() basics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Basic Exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "w = tf.Variable([[2.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w**2\n",
    "\n",
    "d_w = tape.gradient(loss, w)\n",
    "print(d_w.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[8. 8.]\n [8. 8.]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2,2))\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.square(y)\n",
    "d_y= tape.gradient(z, x)\n",
    "print(d_y.numpy())"
   ]
  },
  {
   "source": [
    "### Make the gradient tape persistent\n",
    "To make sure that the gradient tape can be used multiple times, set `persistent=True` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.0])\n",
    "with tf.GradientTape() as tape:\n",
    "    # Record the actions performed on tensor x with `watch`\n",
    "    tape.watch(x)\n",
    "    # Define y as the sum of the elements in x\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.square(y)\n",
    "dz_dx = tape.gradient(z, x)\n",
    "print(dz_dx.numpy())"
   ]
  },
  {
   "source": [
    "### Gradient tape expires after one use, by default\n",
    "\n",
    "If you want to compute multiple gradients, note that by default, GradientTape is not persistent (`persistent=False`).  This means that the GradientTape will expire after you use it to calculate a gradient.\n",
    "\n",
    "To see this, set up gradient tape as usual and calculate a gradient, so that the gradient tape will be 'expired'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A non-persistent GradientTape can only be used tocompute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dy_dx = tape.gradient(y, x)\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "source": [
    "### Make the gradient tape persistent\n",
    "To make sure that the gradient tape can be used multiple times, set `persistent=True` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.0])\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    # Record the actions performed on tensor x with `watch`\n",
    "    tape.watch(x)\n",
    "    # Define y as the sum of the elements in x\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.square(y)\n",
    "dz_dx = tape.gradient(z, x)\n",
    "print(dz_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dy_dx = tape.gradient(y, x)\n",
    "    print(dy_dx.numpy())\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "source": [
    "### Nested Gradient tapes\n",
    "Now let's try computing a higher order derivative by nesting the `GradientTapes:`\n",
    "\n",
    "#### Acceptable indentation of the first gradient calculation\n",
    "Keep in mind that you'll want to make sure that the first gradient calculation of `dy_dx` should occur at least inside the outer `with` block."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### a. without the `persistent=True`, the tape will expire outside the scope, so it can't be used ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[27.]\n[18.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape() as tape2:\n",
    "    with tf.GradientTape() as tape1:\n",
    "        y = x**3\n",
    "    dy_dx = tape1.gradient(y,x)\n",
    "dy2_dx = tape2.gradient(dy_dx, x)\n",
    "\n",
    "print(dy_dx.numpy())\n",
    "print(dy2_dx.numpy())"
   ]
  },
  {
   "source": [
    "### b.  by using, `persistent=True`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([27.], shape=(1,), dtype=float32)\nNone\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape2:\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        y = x**3\n",
    "\n",
    "\n",
    "dy_dx = tape1.gradient(y,x)\n",
    "dy2_dx = tape2.gradient(dy_dx, x)\n",
    "\n",
    "print(dy_dx)\n",
    "print(dy2_dx)"
   ]
  },
  {
   "source": [
    "#### Notice how the `d2y_dx2` calculation is now `None`.  The tape has expired.  Also note that this still won't work even if you set persistent=True for both gradient tapes.\n",
    "\n",
    "### c. Proper indenting is needed."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "[27.]\n",
      "[18.]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([3.0])\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape2:\n",
    "    with tf.GradientTape(persistent=True) as tape1:\n",
    "        y = x**3\n",
    "        dy_dx = tape1.gradient(y,x)\n",
    "    dy2_dx = tape2.gradient(dy_dx, x)\n",
    "\n",
    "print(dy_dx.numpy())\n",
    "print(dy2_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}